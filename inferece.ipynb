{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf860f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n",
      "CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661e1d5",
   "metadata": {},
   "source": [
    "## RUN  ALL  THE CELLs, at the end is the interactive testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4dd353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharVocab class defined\n"
     ]
    }
   ],
   "source": [
    "class CharVocab:\n",
    "    \"\"\"Character-level vocabulary for Georgian text.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.SOS_TOKEN = '<SOS>'  # Start of sequence\n",
    "        self.EOS_TOKEN = '<EOS>'  # End of sequence\n",
    "        self.UNK_TOKEN = '<UNK>'  # Unknown character\n",
    "\n",
    "        self.char2idx = {\n",
    "            self.PAD_TOKEN: 0,\n",
    "            self.SOS_TOKEN: 1,\n",
    "            self.EOS_TOKEN: 2,\n",
    "            self.UNK_TOKEN: 3,\n",
    "        }\n",
    "        self.idx2char = {v: k for k, v in self.char2idx.items()}\n",
    "        self.next_idx = 4\n",
    "\n",
    "    def build_vocab(self, words):\n",
    "        \"\"\"Build vocabulary from list of words.\"\"\"\n",
    "        for word in words:\n",
    "            for char in word:\n",
    "                if char not in self.char2idx:\n",
    "                    self.char2idx[char] = self.next_idx\n",
    "                    self.idx2char[self.next_idx] = char\n",
    "                    self.next_idx += 1\n",
    "        print(f\"Vocabulary size: {len(self.char2idx)}\")\n",
    "        return self\n",
    "\n",
    "    def encode(self, text, add_sos=False, add_eos=True):\n",
    "        \"\"\"Convert text to list of indices.\"\"\"\n",
    "        indices = []\n",
    "        if add_sos:\n",
    "            indices.append(self.char2idx[self.SOS_TOKEN])\n",
    "        indices.extend([self.char2idx.get(char, self.char2idx[self.UNK_TOKEN])\n",
    "                        for char in text])\n",
    "        if add_eos:\n",
    "            indices.append(self.char2idx[self.EOS_TOKEN])\n",
    "        return indices\n",
    "\n",
    "    def decode(self, indices):\n",
    "        \"\"\"Convert list of indices to text.\"\"\"\n",
    "        chars = []\n",
    "        for idx in indices:\n",
    "            if idx == self.char2idx[self.EOS_TOKEN]:\n",
    "                break\n",
    "            if idx == self.char2idx[self.PAD_TOKEN]:\n",
    "                continue\n",
    "            if idx == self.char2idx[self.SOS_TOKEN]:\n",
    "                continue\n",
    "            chars.append(self.idx2char.get(idx, self.UNK_TOKEN))\n",
    "        return ''.join(chars)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.char2idx)\n",
    "\n",
    "print(\"CharVocab class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780643b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined\n"
     ]
    }
   ],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    \"\"\"LSTM Encoder for sequence encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_lengths=None):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if src_lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            outputs, (hidden, cell) = self.lstm(packed)\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        else:\n",
    "            outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Bahdanau (additive) attention mechanism.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, encoder_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim + encoder_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        src_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask == 0, -1e4)\n",
    "        attention_weights = torch.softmax(attention, dim=1)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        context = context.squeeze(1)\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    \"\"\"LSTM Decoder with attention mechanism.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, encoder_dim, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.attention = BahdanauAttention(hidden_dim, encoder_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim + encoder_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim + encoder_dim + embedding_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, hidden, cell, encoder_outputs, mask=None):\n",
    "        embedded = self.dropout(self.embedding(tgt))\n",
    "        context, attn_weights = self.attention(hidden[-1], encoder_outputs, mask)\n",
    "        context = context.unsqueeze(1)\n",
    "        lstm_input = torch.cat([embedded, context], dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        output = output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        embedded = embedded.squeeze(1)\n",
    "        prediction = self.fc_out(torch.cat([output, context, embedded], dim=1))\n",
    "        return prediction, hidden, cell, attn_weights\n",
    "\n",
    "\n",
    "class SpellingLSTM(nn.Module):\n",
    "    \"\"\"LSTM Encoder-Decoder with Attention for spelling correction.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim=256, encoder_hidden_dim=256,\n",
    "                 decoder_hidden_dim=512, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = LSTMEncoder(vocab_size, embedding_dim, encoder_hidden_dim, num_layers, dropout)\n",
    "        encoder_output_dim = encoder_hidden_dim * 2\n",
    "        self.decoder = LSTMDecoder(vocab_size, embedding_dim, decoder_hidden_dim,\n",
    "                                  encoder_output_dim, num_layers, dropout)\n",
    "        self.bridge_h = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.bridge_c = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, **kwargs):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        if src_padding_mask is not None:\n",
    "            src_lengths = (~src_padding_mask).sum(dim=1)\n",
    "        else:\n",
    "            src_lengths = torch.full((batch_size,), src.size(1), dtype=torch.long, device=src.device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "        hidden_combined = []\n",
    "        cell_combined = []\n",
    "        for i in range(self.decoder.num_layers):\n",
    "            h_forward = hidden[i*2]\n",
    "            h_backward = hidden[i*2 + 1]\n",
    "            h_combined = torch.cat([h_forward, h_backward], dim=1)\n",
    "            hidden_combined.append(self.bridge_h(h_combined))\n",
    "            c_forward = cell[i*2]\n",
    "            c_backward = cell[i*2 + 1]\n",
    "            c_combined = torch.cat([c_forward, c_backward], dim=1)\n",
    "            cell_combined.append(self.bridge_c(c_combined))\n",
    "        hidden = torch.stack(hidden_combined)\n",
    "        cell = torch.stack(cell_combined)\n",
    "        attn_mask = None\n",
    "        if src_padding_mask is not None:\n",
    "            attn_mask = ~src_padding_mask\n",
    "        outputs = []\n",
    "        for t in range(tgt_len):\n",
    "            tgt_t = tgt[:, t].unsqueeze(1)\n",
    "            prediction, hidden, cell, _ = self.decoder(tgt_t, hidden, cell, encoder_outputs, attn_mask)\n",
    "            outputs.append(prediction)\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "print(\"Model architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e593830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary from char_vocab.json\n",
      "Vocabulary size: 39\n"
     ]
    }
   ],
   "source": [
    "# Load vocabulary from JSON file\n",
    "vocab_json_path = 'char_vocab.json'\n",
    "\n",
    "with open(vocab_json_path, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "# Reconstruct vocabulary object\n",
    "vocab = CharVocab()\n",
    "vocab.char2idx = vocab_data['char2idx']\n",
    "# Convert string keys back to integers for idx2char\n",
    "vocab.idx2char = {int(k): v for k, v in vocab_data['idx2char'].items()}\n",
    "vocab.next_idx = vocab_data.get('next_idx', len(vocab.char2idx))\n",
    "\n",
    "print(f\"Loaded vocabulary from {vocab_json_path}\")\n",
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4909b756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Trained for 8 epochs\n",
      "Best validation loss: 1.001819218268417\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with same parameters as training\n",
    "model = SpellingLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=256,\n",
    "    encoder_hidden_dim=256,\n",
    "    decoder_hidden_dim=512,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load('best_model1.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Trained for {checkpoint.get('epoch', 'unknown')} epochs\")\n",
    "print(f\"Best validation loss: {checkpoint.get('val_loss', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b3e01",
   "metadata": {},
   "source": [
    "## Step 6: Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa91bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference function defined\n"
     ]
    }
   ],
   "source": [
    "def correct_word(model, word, vocab, device='cuda', max_len=100):\n",
    "    \"\"\"\n",
    "    Correct a single misspelled word using LSTM decoder.\n",
    "    \n",
    "    Uses greedy decoding with early stopping to prevent loops.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode input (no SOS for source)\n",
    "    src = torch.LongTensor([vocab.encode(word, add_sos=False, add_eos=True)]).to(device)\n",
    "    src_lengths = torch.LongTensor([src.size(1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode source\n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_lengths)\n",
    "        \n",
    "        # Bridge encoder hidden to decoder\n",
    "        hidden_combined = []\n",
    "        cell_combined = []\n",
    "        for i in range(model.decoder.num_layers):\n",
    "            h_forward = hidden[i*2]\n",
    "            h_backward = hidden[i*2 + 1]\n",
    "            h_combined = torch.cat([h_forward, h_backward], dim=1)\n",
    "            hidden_combined.append(model.bridge_h(h_combined))\n",
    "            \n",
    "            c_forward = cell[i*2]\n",
    "            c_backward = cell[i*2 + 1]\n",
    "            c_combined = torch.cat([c_forward, c_backward], dim=1)\n",
    "            cell_combined.append(model.bridge_c(c_combined))\n",
    "        \n",
    "        hidden = torch.stack(hidden_combined)\n",
    "        cell = torch.stack(cell_combined)\n",
    "        \n",
    "        # Start with SOS token\n",
    "        tgt_token = torch.LongTensor([[vocab.char2idx['<SOS>']]]).to(device)\n",
    "        decoded_tokens = []\n",
    "        \n",
    "        # Greedy decoding with loop prevention\n",
    "        for step in range(max_len):\n",
    "            prediction, hidden, cell, _ = model.decoder(\n",
    "                tgt_token, hidden, cell, encoder_outputs, mask=None\n",
    "            )\n",
    "            \n",
    "            # Get most likely next token\n",
    "            next_token_id = prediction.argmax(dim=-1).item()\n",
    "            \n",
    "            # Stop conditions\n",
    "            if next_token_id == vocab.char2idx['<EOS>']:\n",
    "                break\n",
    "            if next_token_id == vocab.char2idx['<PAD>']:\n",
    "                break\n",
    "            if next_token_id == vocab.char2idx['<SOS>']:\n",
    "                continue  # Skip if model predicts SOS again\n",
    "            \n",
    "            # Prevent infinite loops: stop if output is too long relative to input\n",
    "            if len(decoded_tokens) > len(word) * 3:\n",
    "                break\n",
    "            \n",
    "            # Detect repetition: if last 3 characters are same, stop\n",
    "            if len(decoded_tokens) >= 3:\n",
    "                last_three = decoded_tokens[-3:]\n",
    "                if len(set(last_three)) == 1:  # All same character\n",
    "                    break\n",
    "            \n",
    "            decoded_tokens.append(next_token_id)\n",
    "            tgt_token = torch.LongTensor([[next_token_id]]).to(device)\n",
    "    \n",
    "    # Decode tokens to string\n",
    "    return vocab.decode(decoded_tokens)\n",
    "\n",
    "print(\"Inference function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3730c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35 Georgian characters from vocabulary\n",
      "Corruption function defined\n"
     ]
    }
   ],
   "source": [
    "# Define corruption function for testing\n",
    "import random\n",
    "\n",
    "GEORGIAN_KEYBOARD = {\n",
    "   \"ა\": ['ქ','ს','ზ'], 'ბ': ['ვ','ნ','გ','ჰ'], 'გ': ['ვ','ბ','ფ','ტ','ყ','ჰ'],\n",
    "   'დ': ['ხ','ც','ს','ფ','რ','ე'], 'ე': ['წ','რ','დ','ს'], 'ვ': ['ც','ბ','ფ','გ'],\n",
    "   'ზ': ['ა','ს','ხ'], \"თ\": ['ღ','ყ','ფ','გ','ტ','რ'], 'ი': ['უ','ო','ჯ','კ'],\n",
    "   'კ': ['მ','ჯ','ლ','ი','ო'], 'ლ': ['კ','ო','პ'], 'მ': ['ნ','ჯ','კ','ლ'],\n",
    "   'ნ': ['ბ','ჰ','ჯ'], 'ო': ['ი','პ','კ','ლ'], 'პ': ['ო','ლ'],\n",
    "   'ჟ': ['ჯ','ჰ','უ','ნ','მ'], 'რ': ['ღ','ე','ტ','თ','დ','ფ'],\n",
    "   'ს': ['შ','ა','ზ','ხ','წ','ე'], 'ტ': ['რ','ყ','ფ','გ'], 'უ': ['ყ','ჰ','ჯ','ი'],\n",
    "   'ფ': ['ც','ვ','დ','გ','რ','ტ'], 'ქ': ['ა','წ'], 'ღ': ['თ','რ','ტ','ე','დ','ფ'],\n",
    "   'ყ': ['ტ','გ','ჰ','უ'], 'შ': ['ს','ა','დ','წ','ე','ხ'], 'ჩ': ['ც','ხ','ვ','დ','ფ'],\n",
    "   'ც': ['ხ','ვ','დ','ფ'], 'ძ': ['ა','ს','ხ'], 'წ': ['ქ','ე','ს','ა'],\n",
    "   'ჭ': ['ქ','ე','ს','ა'], 'ხ': ['ა','ს','დ','ც','ზ'],\n",
    "   'ჯ': ['ჰ','უ','ი','კ','მ','ნ'], 'ჰ': ['გ','ყ','უ','ჯ','ნ','ბ']\n",
    "}\n",
    "\n",
    "# Get all Georgian characters from vocabulary (excluding special tokens)\n",
    "ALL_GEORGIAN_CHARS = set()\n",
    "for char in vocab.char2idx.keys():\n",
    "    if char not in [vocab.PAD_TOKEN, vocab.SOS_TOKEN, vocab.EOS_TOKEN, vocab.UNK_TOKEN]:\n",
    "        ALL_GEORGIAN_CHARS.add(char)\n",
    "\n",
    "print(f\"Loaded {len(ALL_GEORGIAN_CHARS)} Georgian characters from vocabulary\")\n",
    "\n",
    "def corrupt_word(word, corruption_prob=1.0):\n",
    "    \"\"\"Apply realistic corruptions to simulate typing errors.\"\"\"\n",
    "    if len(word) < 2:\n",
    "        return word\n",
    "    \n",
    "    original_word = word\n",
    "    max_attempts = 10\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        word_list = list(original_word)\n",
    "        \n",
    "        # Number of errors based on word length\n",
    "        if len(word_list) <= 4:\n",
    "            num_errors = 1\n",
    "        elif len(word_list) <= 8:\n",
    "            num_errors = random.randint(1, 2)\n",
    "        else:\n",
    "            num_errors = random.randint(1, 3)\n",
    "        \n",
    "        for _ in range(num_errors):\n",
    "            if len(word_list) < 2:\n",
    "                break\n",
    "            \n",
    "            error_type = random.choices(\n",
    "                ['substitute', 'delete', 'insert', 'transpose', 'repeat'],\n",
    "                weights=[0.35, 0.25, 0.20, 0.15, 0.05]\n",
    "            )[0]\n",
    "            \n",
    "            pos = random.randint(0, len(word_list) - 1)\n",
    "            \n",
    "            if error_type == 'substitute':\n",
    "                char = word_list[pos]\n",
    "                if char in GEORGIAN_KEYBOARD and GEORGIAN_KEYBOARD[char]:\n",
    "                    word_list[pos] = random.choice(GEORGIAN_KEYBOARD[char])\n",
    "                elif ALL_GEORGIAN_CHARS:\n",
    "                    candidates = [c for c in ALL_GEORGIAN_CHARS if c != char]\n",
    "                    if candidates:\n",
    "                        word_list[pos] = random.choice(candidates)\n",
    "            \n",
    "            elif error_type == 'delete':\n",
    "                if len(word_list) > 2:\n",
    "                    word_list.pop(pos)\n",
    "            \n",
    "            elif error_type == 'insert':\n",
    "                if ALL_GEORGIAN_CHARS:\n",
    "                    if pos > 0 and random.random() < 0.3:\n",
    "                        word_list.insert(pos, word_list[pos-1])\n",
    "                    else:\n",
    "                        word_list.insert(pos, random.choice(list(ALL_GEORGIAN_CHARS)))\n",
    "            \n",
    "            elif error_type == 'transpose':\n",
    "                if pos < len(word_list) - 1:\n",
    "                    word_list[pos], word_list[pos + 1] = word_list[pos + 1], word_list[pos]\n",
    "            \n",
    "            elif error_type == 'repeat':\n",
    "                word_list.insert(pos, word_list[pos])\n",
    "        \n",
    "        corrupted = ''.join(word_list)\n",
    "        \n",
    "        if corrupted != original_word and len(corrupted) > 0:\n",
    "            return corrupted\n",
    "    \n",
    "    # Last resort: force a substitution\n",
    "    if len(original_word) >= 2 and ALL_GEORGIAN_CHARS:\n",
    "        word_list = list(original_word)\n",
    "        pos = random.randint(0, len(word_list) - 1)\n",
    "        candidates = [c for c in ALL_GEORGIAN_CHARS if c != word_list[pos]]\n",
    "        if candidates:\n",
    "            word_list[pos] = random.choice(candidates)\n",
    "            return ''.join(word_list)\n",
    "    \n",
    "    return original_word\n",
    "\n",
    "print(\"Corruption function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2347335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 20 test pairs\n",
      "\n",
      "All test examples:\n",
      " 1. Corrupted: გზმაეჯობბა           → Original: გამარჯობა\n",
      " 2. Corrupted: ჯადლიბა              → Original: მადლობა\n",
      " 3. Corrupted: დედ                  → Original: დედა\n",
      " 4. Corrupted: მანა                 → Original: მამა\n",
      " 5. Corrupted: საახლი               → Original: სახლი\n",
      " 6. Corrupted: წიგგნი               → Original: წიგნი\n",
      " 7. Corrupted: ზკოლა                → Original: სკოლა\n",
      " 8. Corrupted: ყმეგობრი             → Original: მეგობარი\n",
      " 9. Corrupted: ქუფა                 → Original: ქუჩა\n",
      "10. Corrupted: სქატთველო            → Original: საქართველო\n",
      "11. Corrupted: თბიისი               → Original: თბილისი\n",
      "12. Corrupted: ბაბშვ-ი              → Original: ბავშვი\n",
      "13. Corrupted: ქპალი                → Original: ქალი\n",
      "14. Corrupted: კაცჯ                 → Original: კაცი\n",
      "15. Corrupted: მძაღლი               → Original: ძაღლი\n",
      "16. Corrupted: კაატ                 → Original: კატა\n",
      "17. Corrupted: სზმჭელი              → Original: საჭმელი\n",
      "18. Corrupted: წყაყლი               → Original: წყალი\n",
      "19. Corrupted: ცრო                  → Original: დრო\n",
      "20. Corrupted: ფუბლი                → Original: ფული\n"
     ]
    }
   ],
   "source": [
    "# Create test pairs: corrupt some sample Georgian words\n",
    "random.seed(42)\n",
    "\n",
    "# Sample Georgian words for testing (you can replace these with your own)\n",
    "sample_words = [\n",
    "    'გამარჯობა', 'მადლობა', 'დედა', 'მამა', 'სახლი', \n",
    "    'წიგნი', 'სკოლა', 'მეგობარი', 'ქუჩა', 'საქართველო',\n",
    "    'თბილისი', 'ბავშვი', 'ქალი', 'კაცი', 'ძაღლი',\n",
    "    'კატა', 'საჭმელი', 'წყალი', 'დრო', 'ფული'\n",
    "]\n",
    "\n",
    "test_pairs = []\n",
    "for word in sample_words:\n",
    "    corrupted = corrupt_word(word)\n",
    "    if corrupted != word:  # Only add if actually corrupted\n",
    "        test_pairs.append((corrupted, word))\n",
    "\n",
    "print(f\"Created {len(test_pairs)} test pairs\")\n",
    "print(\"\\nAll test examples:\")\n",
    "for i, (corrupted, original) in enumerate(test_pairs, 1):\n",
    "    print(f\"{i:2}. Corrupted: {corrupted:20} → Original: {original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1294c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score calculation function defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_f1_score(predicted, target):\n",
    "    \"\"\"\n",
    "    Calculate character-level F1 score between predicted and target strings.\n",
    "    \n",
    "    Args:\n",
    "        predicted: The predicted/corrected word\n",
    "        target: The true/original word\n",
    "    \n",
    "    Returns:\n",
    "        f1_score: F1 score value (0 to 1)\n",
    "    \"\"\"\n",
    "    # Convert to sets of (character, position) pairs for character-level matching\n",
    "    pred_chars = set((char, i) for i, char in enumerate(predicted))\n",
    "    target_chars = set((char, i) for i, char in enumerate(target))\n",
    "    \n",
    "    # Calculate true positives, false positives, false negatives\n",
    "    true_positives = len(pred_chars & target_chars)\n",
    "    false_positives = len(pred_chars - target_chars)\n",
    "    false_negatives = len(target_chars - pred_chars)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "print(\"F1 score calculation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad52712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing Model on Corrupted Word Pairs\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Corrupted: გზმაეჯობბა           → Corrected: გამარჯობა            (True: გამარჯობა) | F1: 1.000\n",
      "✗ Corrupted: ჯადლიბა              → Corrected: ჯადობია              (True: მადლობა) | F1: 0.429\n",
      "✓ Corrupted: დედ                  → Corrected: დედა                 (True: დედა) | F1: 1.000\n",
      "✗ Corrupted: მანა                 → Corrected: მანას                (True: მამა) | F1: 0.667\n",
      "✗ Corrupted: საახლი               → Corrected: სახალი               (True: სახლი) | F1: 0.545\n",
      "✓ Corrupted: წიგგნი               → Corrected: წიგნი                (True: წიგნი) | F1: 1.000\n",
      "✗ Corrupted: ზკოლა                → Corrected: აკოლა                (True: სკოლა) | F1: 0.800\n",
      "✗ Corrupted: ყმეგობრი             → Corrected: მეგობრი              (True: მეგობარი) | F1: 0.667\n",
      "✗ Corrupted: ქუფა                 → Corrected: ქუდა                 (True: ქუჩა) | F1: 0.750\n",
      "✓ Corrupted: სქატთველო            → Corrected: საქართველო           (True: საქართველო) | F1: 1.000\n",
      "✗ Corrupted: თბიისი               → Corrected: თბისი                (True: თბილისი) | F1: 0.667\n",
      "✓ Corrupted: ბაბშვ-ი              → Corrected: ბავშვი               (True: ბავშვი) | F1: 1.000\n",
      "✓ Corrupted: ქპალი                → Corrected: ქალი                 (True: ქალი) | F1: 1.000\n",
      "✓ Corrupted: კაცჯ                 → Corrected: კაცი                 (True: კაცი) | F1: 1.000\n",
      "✗ Corrupted: მძაღლი               → Corrected: მძღალი               (True: ძაღლი) | F1: 0.182\n",
      "✓ Corrupted: კაატ                 → Corrected: კატა                 (True: კატა) | F1: 1.000\n",
      "✗ Corrupted: სზმჭელი              → Corrected: სამჭელი              (True: საჭმელი) | F1: 0.714\n",
      "✓ Corrupted: წყაყლი               → Corrected: წყალი                (True: წყალი) | F1: 1.000\n",
      "✗ Corrupted: ცრო                  → Corrected: ცრო                  (True: დრო) | F1: 0.667\n",
      "✓ Corrupted: ფუბლი                → Corrected: ფული                 (True: ფული) | F1: 1.000\n",
      "\n",
      "======================================================================\n",
      "Accuracy: 10/20 (50.0%)\n",
      "Average F1 Score: 0.8043\n",
      "Min F1: 0.1818, Max F1: 1.0000\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the model on corrupted pairs\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Testing Model on Corrupted Word Pairs\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "correct_count = 0\n",
    "total_count = len(test_pairs)\n",
    "total_f1 = 0.0\n",
    "f1_scores = []\n",
    "\n",
    "for corrupted_word, original_word in test_pairs:\n",
    "    try:\n",
    "        corrected = correct_word(model, corrupted_word, vocab, device)\n",
    "        is_correct = (corrected == original_word)\n",
    "        correct_count += int(is_correct)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = calculate_f1_score(corrected, original_word)\n",
    "        f1_scores.append(f1)\n",
    "        total_f1 += f1\n",
    "        \n",
    "        status = \"✓\" if is_correct else \"✗\"\n",
    "        print(f\"{status} Corrupted: {corrupted_word:20} → Corrected: {corrected:20} (True: {original_word}) | F1: {f1:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error with '{corrupted_word}': {e}\")\n",
    "        f1_scores.append(0.0)\n",
    "\n",
    "# Calculate average F1 score\n",
    "avg_f1 = total_f1 / total_count if total_count > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Accuracy: {correct_count}/{total_count} ({100*correct_count/total_count:.1f}%)\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"Min F1: {min(f1_scores):.4f}, Max F1: {max(f1_scores):.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e9214",
   "metadata": {},
   "source": [
    "techincally 50% because ბავშვნი ერთ-ერთ ბრუნვაშია, i have over-complicated the data generation imho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05fdaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Georgian word to correct (type 'exit' to quit):\n",
      "  Original:  სალადინი\n",
      "  Corrected: სალადინის\n",
      "\n",
      "  Original:  დანია\n",
      "  Corrected: დანისა\n",
      "\n",
      "  Original:  ალმასი\n",
      "  Corrected: ალმასი\n",
      "\n",
      "  Original:  სტალინი\n",
      "  Corrected: სტალინის\n",
      "\n",
      "  Original:  გიორგა\n",
      "  Corrected: გიორგა\n",
      "\n",
      "  Original:  სააკაძე\n",
      "  Corrected: სააკაძე\n",
      "\n",
      "Exiting interactive correction.\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter a Georgian word to correct (type 'exit' to quit):\")\n",
    "while True:\n",
    "    user_input = input(\"Your word: \").strip()\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    if not user_input:\n",
    "        print(\"Please enter a word.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        corrected_word = correct_word(model, user_input, vocab, device)\n",
    "        print(f\"  Original:  {user_input}\")\n",
    "        print(f\"  Corrected: {corrected_word}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Please try a different word.\\n\")\n",
    "\n",
    "print(\"Exiting interactive correction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4e717",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
