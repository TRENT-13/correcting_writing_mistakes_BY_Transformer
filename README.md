# Georgian Spelling Correction with LSTM Encoder-Decoder

A deep learning system for automatic spelling correction of Georgian text using a bidirectional LSTM encoder-decoder architecture with Bahdanau attention mechanism. The model operates at the character level to correct typographical errors, transpositions, insertions, deletions, and other common spelling mistakes in Georgian words.

## Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Dataset](#dataset)
4. [Technical Details](#technical-details)
5. [Installation](#installation)
6. [Usage](#usage)
7. [Training](#training)
8. [Performance](#performance)
9. [Project Structure](#project-structure)
10. [Requirements](#requirements)

## Overview

This project implements a sequence-to-sequence model for Georgian spelling correction. The system learns to map corrupted Georgian words to their correct spellings by training on synthetic data generated through realistic typing error simulation. The character-level approach enables the model to handle previously unseen misspellings and generalize across the entire vocabulary.

### Key Features

- Character-level processing for robust generalization
- Bidirectional LSTM encoder for full context understanding
- Bahdanau attention mechanism for improved alignment
- Mixed precision (FP16) training for efficiency
- Realistic typing error simulation based on Georgian keyboard layout
- Supports multiple error types: substitutions, deletions, insertions, transpositions, and repetitions

## Architecture

### Model Components

The spelling correction system uses an encoder-decoder architecture with attention:

#### 1. Encoder (Bidirectional LSTM)
- 2-layer bidirectional LSTM
- 256 hidden units per direction (512 total output dimension)
- Processes the corrupted input word character by character
- Captures both left-to-right and right-to-left context
- Output: sequence of hidden states representing the corrupted word

#### 2. Bridge Layer
- Linear transformations to convert bidirectional encoder states to decoder states
- Separate transformations for hidden states (h) and cell states (c)
- Maps from 512 dimensions (encoder) to 512 dimensions (decoder)

#### 3. Decoder (Unidirectional LSTM with Attention)
- 2-layer unidirectional LSTM
- 512 hidden units
- Bahdanau (additive) attention mechanism
- Generates corrected characters autoregressively
- Attention allows the decoder to focus on relevant parts of the input

#### 4. Attention Mechanism
- Type: Bahdanau (additive) attention
- Computes alignment scores between decoder state and encoder outputs
- Produces context vector as weighted sum of encoder outputs
- Enables the model to "look back" at the input while generating corrections

### Architecture Diagram

```
Input: "გაამრჯობა" (corrupted)
    ↓
[Character Embedding Layer: 256 dims]
    ↓
[Bidirectional LSTM Encoder: 2 layers × 256 hidden units]
    ↓
[Bridge Layer: Linear projection 512 → 512]
    ↓
[LSTM Decoder with Attention: 2 layers × 512 hidden units]
    ↓
[Output Projection: 512 → vocab_size (39)]
    ↓
Output: "გამარჯობა" (corrected)
```

### Why LSTM for This Task?

1. **Sequential Nature**: Characters in words have strong sequential dependencies that LSTMs naturally capture
2. **Variable Length**: LSTM encoder-decoder handles variable-length input and output sequences elegantly
3. **Memory Mechanism**: LSTM gates effectively maintain relevant information across the sequence
4. **Proven Performance**: Encoder-decoder with attention is well-established for sequence-to-sequence tasks
5. **Efficiency**: More memory-efficient than Transformers for the relatively short sequences typical of words

### Why Character-Level Processing?

1. **Small Vocabulary**: Georgian alphabet has only 33 letters, resulting in a compact vocabulary of 39 tokens (including special tokens)
2. **Error Granularity**: Spelling errors occur at the character level (typos, adjacent key presses)
3. **Generalization**: Can handle any misspelling, including out-of-vocabulary words
4. **No Segmentation**: Avoids complexity of word-level tokenization

## Dataset

### Data Source

The model is trained on a corpus of Georgian words split into three data files:
- `wordsChunk_0.json`: 100,000 words
- `wordsChunk_1.json`: 100,000 words
- `wordsChunk_2.json`: 71,788 words

Total: Approximately 271,788 Georgian words

### Data Corruption Strategy

Training pairs are generated by synthetically corrupting correct Georgian words. The corruption process simulates realistic typing errors:

#### Error Types and Frequencies

1. **Substitution (35%)**: Replace character with adjacent key on Georgian keyboard
   - Example: "გ" → "ვ" (adjacent keys)
   - Uses Georgian QWERTY keyboard layout mapping

2. **Deletion (25%)**: Remove a character
   - Example: "გამარჯობა" → "გმარჯობა"

3. **Insertion (20%)**: Add an extra character
   - Random Georgian character or duplication of adjacent character
   - Example: "გამარჯობა" → "გამმარჯობა"

4. **Transposition (15%)**: Swap two adjacent characters
   - Example: "გამარჯობა" → "გმაარჯობა"

5. **Repetition (5%)**: Duplicate a character
   - Example: "გამარჯობა" → "გაამარჯობა"

#### Corruption Parameters

- Number of errors per word: 1-3 depending on word length
  - Short words (≤4 chars): 1 error
  - Medium words (5-8 chars): 1-2 errors
  - Long words (>8 chars): 1-3 errors
- Corruption rate: 100% (all training examples are corrupted)
- Minimum word length: 2 characters

### Vocabulary

The character vocabulary consists of:
- 33 Georgian letters (ა, ბ, გ, დ, ე, ვ, ზ, თ, ι, კ, ლ, მ, ν, ო, პ, ჟ, რ, ს, ტ, უ, φ, ქ, ღ, ყ, შ, ჩ, ც, ძ, წ, ჭ, ხ, ჯ, ჰ)
- 2 punctuation marks (-, ,)
- 4 special tokens:
  - `<PAD>`: Padding token (index 0)
  - `<SOS>`: Start of sequence (index 1)
  - `<EOS>`: End of sequence (index 2)
  - `<UNK>`: Unknown character (index 3)

Total vocabulary size: 39 tokens

The vocabulary mapping is stored in `char_vocab.json` for consistency between training and inference.

## Technical Details

### Model Parameters

```
Total parameters: ~6.7 million
- Embedding dimension: 256
- Encoder hidden dimension: 256 (per direction)
- Decoder hidden dimension: 512
- Number of layers: 2
- Dropout rate: 0.3
```

### Training Configuration

**Optimization:**
- Optimizer: Adam
- Initial learning rate: 0.001
- Learning rate scheduler: ReduceLROnPlateau
  - Factor: 0.5
  - Patience: 2 epochs
- Gradient clipping: max norm 1.0

**Loss Function:**
- CrossEntropyLoss with label smoothing (0.1)
- Ignores padding tokens in loss calculation

**Mixed Precision Training:**
- FP16 (float16) for forward and backward passes
- Gradient scaling to prevent underflow
- Reduces memory usage and increases training speed

**Regularization:**
- Dropout: 0.3 (applied in embedding and LSTM layers)
- Label smoothing: 0.1
- Gradient clipping: prevents exploding gradients

**Training Strategy:**
- Teacher forcing: ground truth used as decoder input during training
- Early stopping: patience of 5 epochs on validation loss
- Train/validation split: 90%/10%
- Batch size: 128

### Inference

The model uses greedy decoding for inference:

1. Encode the corrupted word with the bidirectional encoder
2. Initialize decoder with `<SOS>` token
3. At each step:
   - Decoder predicts probability distribution over characters
   - Select character with highest probability (greedy)
   - Use predicted character as input for next step
   - Apply attention to focus on relevant input positions
4. Stop when `<EOS>` token is generated or maximum length is reached

### Attention Mechanism Details

The Bahdanau attention computes a context vector at each decoding step:

1. **Score calculation**: For each encoder output, compute alignment score using decoder hidden state
   ```
   score(h_decoder, h_encoder_i) = v^T * tanh(W1 * h_decoder + W2 * h_encoder_i)
   ```

2. **Attention weights**: Apply softmax to scores to get normalized weights
   ```
   attention_weights = softmax(scores)
   ```

3. **Context vector**: Weighted sum of encoder outputs
   ```
   context = Σ(attention_weights_i * encoder_output_i)
   ```

4. **Integration**: Concatenate context with decoder input before LSTM

This mechanism allows the decoder to dynamically focus on different parts of the corrupted input while generating each character of the correction.

## Installation

### Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (recommended) or CPU
- 4GB+ RAM
- 2GB+ disk space (for model checkpoint)

### Setup

1. Clone the repository:
```bash
git clone https://github.com/TRENT-13/correcting_writing_mistakes_BY_Transformer.git
cd correcting_writing_mistakes_BY_Transformer
```

2. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install numpy tqdm jupyter
```

### Required Packages

```
torch>=2.0.0
numpy>=1.21.0
tqdm>=4.62.0
jupyter>=1.0.0
```

For CPU-only installation:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

For CUDA 11.8:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## Usage

### Running the Inference Notebook

The easiest way to use the pre-trained model is through the inference notebook:

1. Open the inference notebook:
```bash
jupyter notebook inferece.ipynb
```

2. Run all cells in sequence. The notebook will:
   - Load the pre-trained model from `best_model1.pt`
   - Load the vocabulary from `char_vocab.json`
   - Set up the correction function
   - Provide an interactive testing interface

3. Test with your own Georgian words:
```python
# Example usage in the notebook
test_word = "გაამრჯობა"  # Corrupted word
corrected = correct_word(model, test_word, vocab, device=device)
print(f"Input: {test_word}")
print(f"Corrected: {corrected}")
```

### Programmatic Usage

You can also use the model programmatically:

```python
import torch
import json
from pathlib import Path

# Load vocabulary
with open('char_vocab.json', 'r', encoding='utf-8') as f:
    vocab_data = json.load(f)

# Reconstruct vocabulary object
vocab = CharVocab()
vocab.char2idx = vocab_data['char2idx']
vocab.idx2char = {int(k): v for k, v in vocab_data['idx2char'].items()}

# Load model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SpellingLSTM(
    vocab_size=len(vocab),
    embedding_dim=256,
    encoder_hidden_dim=256,
    decoder_hidden_dim=512,
    num_layers=2,
    dropout=0.3
)

checkpoint = torch.load('best_model1.pt', map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.to(device)
model.eval()

# Correct a word
def correct_word(model, word, vocab, device='cuda', max_len=100):
    # Implementation as shown in inferece.ipynb
    pass

# Usage
corrected = correct_word(model, "გაამრჯობა", vocab, device)
print(corrected)  # Output: "გამარჯობა"
```

### Interactive Testing

The inference notebook includes an interactive testing section at the end:

```python
# Interactive testing
while True:
    word = input("Enter Georgian word (or 'quit' to exit): ")
    if word.lower() == 'quit':
        break

    corrected = correct_word(model, word, vocab, device)
    print(f"Corrected: {corrected}\n")
```

## Training

### Training from Scratch

To train the model from scratch, use the training notebook:

1. Ensure data files are in the `data/` directory:
   - `data/wordsChunk_0.json`
   - `data/wordsChunk_1.json`
   - `data/wordsChunk_2.json`

2. Open the training notebook:
```bash
jupyter notebook Train_Test.ipynb
```

3. Modify training parameters if desired:
```python
CORRUPTION_RATE = 1.0        # 100% corruption rate
MAX_WORDS = None             # Use all words (or set limit for testing)
BATCH_SIZE = 128             # Batch size (reduce if OOM)
NUM_EPOCHS = 15              # Maximum number of epochs
LEARNING_RATE = 0.001        # Initial learning rate
```

4. Run all cells in sequence. The training process will:
   - Load and corrupt the dataset
   - Build the character vocabulary
   - Split data into train/validation sets (90%/10%)
   - Initialize the model
   - Train with mixed precision (FP16)
   - Save the best model based on validation loss
   - Test on example corrections

### Training Time

On a GPU (e.g., NVIDIA Tesla T4):
- Time per epoch: ~3-4 minutes
- Total training time: ~45-60 minutes (with early stopping)

On CPU:
- Time per epoch: ~30-40 minutes
- Total training time: ~7-10 hours

### Monitoring Training

The training loop displays:
- Real-time progress bar with loss and accuracy
- Per-epoch summary:
  - Train loss and accuracy
  - Validation loss and accuracy
  - Learning rate
  - Model checkpoint saves

Example output:
```
Epoch 8/15: 100%|██████████| 1911/1911 [03:12<00:00, 9.93it/s, loss=1.0145, acc=92.12%]
Epoch 8 Summary:
  Train Loss: 1.0234 | Train Acc: 92.12%
  Val Loss: 1.0018 | Val Acc: 89.52%
  Saved best model (val_loss: 1.0018)
```

### Resuming Training

To resume training from a checkpoint:

```python
# Load checkpoint
checkpoint = torch.load('best_model1.pt', map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch'] + 1

# Continue training
for epoch in range(start_epoch, NUM_EPOCHS):
    # Training loop...
```

## Performance

### Metrics

The model achieves the following performance on the validation set:

- **Validation Loss**: 1.0018 (after 8 epochs)
- **Character-Level Accuracy**: 89.52%
- **Training Accuracy**: 92.12%

### Sample Corrections

Examples of successful corrections:

| Corrupted Input | Model Output | Ground Truth | Status |
|----------------|--------------|--------------|--------|
| ოქროოიპროიბთ | ოქროპირობით | ოქროპირობით | Correct |
| პ-ეში | პეში | პეში | Correct |
| გაუჭირვწბლადდ | გაუჭირვებლად | გაუჭირვებლად | Correct |
| უყვარრადა | უყვარადა | უყვარადა | Correct |

The model successfully handles multiple error types including substitutions, deletions, insertions, and transpositions.

### Limitations

1. **Multiple Corrections**: Complex words with many errors may not be fully corrected
2. **Rare Characters**: Less common Georgian characters may have lower accuracy
3. **Context**: Model operates on isolated words without sentence context
4. **Ambiguity**: Cannot resolve ambiguous corrections without semantic understanding

### Convergence

- Early stopping typically triggers around epoch 8-14
- Model achieves ~90% character accuracy within 10 epochs
- Additional epochs show diminishing returns due to overfitting

## Project Structure

```
correcting_writing_mistakes_BY_Transformer/
├── data/
│   ├── wordsChunk_0.json      # Georgian word corpus (100K words)
│   ├── wordsChunk_1.json      # Georgian word corpus (100K words)
│   └── wordsChunk_2.json      # Georgian word corpus (71K words)
├── Train_Test.ipynb           # Training notebook with full pipeline
├── inferece.ipynb             # Inference notebook for testing model
├── explanation.ipynb          # Detailed model explanation and theory
├── best_model1.pt             # Pre-trained model checkpoint (97MB)
├── char_vocab.json            # Character vocabulary mapping
├── DL_Assignment 2.pdf        # Assignment description
└── README.md                  # This file
```

### File Descriptions

**Data Files:**
- `data/wordsChunk_*.json`: JSON files containing arrays of Georgian words used for training

**Notebooks:**
- `Train_Test.ipynb`: Complete training pipeline including data loading, corruption, model definition, training loop, and evaluation
- `inferece.ipynb`: Inference interface for loading pre-trained model and correcting words
- `explanation.ipynb`: Theoretical explanation of the approach, architecture, and design choices

**Model Files:**
- `best_model1.pt`: PyTorch checkpoint containing:
  - Model state dictionary (trained weights)
  - Optimizer state dictionary
  - Training epoch number
  - Best validation loss
- `char_vocab.json`: Character-to-index and index-to-character mappings for consistent encoding/decoding

## Requirements

### System Requirements

**Minimum:**
- CPU: Multi-core processor (4+ cores recommended)
- RAM: 4GB
- Storage: 2GB free space
- OS: Windows 10, macOS 10.14+, or Linux

**Recommended:**
- GPU: NVIDIA GPU with 4GB+ VRAM (e.g., GTX 1650, RTX 3060)
- RAM: 8GB
- Storage: 5GB free space (for data and checkpoints)
- CUDA: 11.8 or later

### Python Dependencies

```
Python >= 3.8
torch >= 2.0.0
numpy >= 1.21.0
tqdm >= 4.62.0
jupyter >= 1.0.0
```

### Installation via pip

```bash
pip install torch numpy tqdm jupyter
```

### Installation via conda

```bash
conda create -n georgian-spelling python=3.9
conda activate georgian-spelling
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
conda install numpy tqdm jupyter -c conda-forge
```

## Technical Implementation Notes

### Mixed Precision Training

The implementation uses PyTorch's Automatic Mixed Precision (AMP) for efficient training:

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

# Training step
optimizer.zero_grad()
with autocast():
    output = model(src, tgt_input)
    loss = criterion(output, tgt_output)

scaler.scale(loss).backward()
scaler.unscale_(optimizer)
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
scaler.step(optimizer)
scaler.update()
```

Benefits:
- 2-3x faster training
- 40-50% reduction in memory usage
- Maintains model accuracy with FP16

### Gradient Clipping

Gradient norms are clipped to prevent exploding gradients:

```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

This is particularly important for recurrent networks (LSTMs) which are prone to gradient instability.

### Teacher Forcing

During training, the decoder receives ground truth tokens as input (teacher forcing):

```python
tgt_input = tgt[:, :-1]   # Ground truth without last token
tgt_output = tgt[:, 1:]   # Ground truth shifted by 1

output = model(src, tgt_input)  # Teacher forcing
```

This accelerates training convergence by providing correct context at each decoding step.

### Padding and Masking

Variable-length sequences are handled with padding and masking:

```python
# Create padding masks
src_padding_mask = (src == vocab.char2idx['<PAD>'])
tgt_padding_mask = (tgt_input == vocab.char2idx['<PAD>'])

# Ignore padding in loss
criterion = nn.CrossEntropyLoss(ignore_index=vocab.char2idx['<PAD>'])
```

This ensures padding tokens do not contribute to gradient updates or loss calculation.

### Sequence Packing

The encoder uses packed sequences for efficient LSTM processing:

```python
packed = nn.utils.rnn.pack_padded_sequence(
    embedded, src_lengths, batch_first=True, enforce_sorted=False
)
packed_output, (hidden, cell) = self.lstm(packed)
encoder_outputs, _ = nn.utils.rnn.pad_packed_sequence(
    packed_output, batch_first=True
)
```

This avoids unnecessary computation on padding tokens and improves training speed.

## Citation

If you use this code or model in your research, please cite:

```
@misc{georgian-spelling-correction-2024,
  author = {TRENT-13},
  title = {Georgian Spelling Correction with LSTM Encoder-Decoder},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/TRENT-13/correcting_writing_mistakes_BY_Transformer}
}
```

## License

This project is available for educational and research purposes.

## Acknowledgments

- Georgian word corpus used for training
- PyTorch framework for deep learning implementation
- Bahdanau et al. for the attention mechanism design
- Sequence-to-sequence learning methodology from Sutskever et al.

## Contact

For questions or issues, please open an issue on the GitHub repository.
